{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aICgj7Hpw8S3"
      },
      "outputs": [],
      "source": [
        "# %pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-experimental neo4j wikipedia tiktoken yfiles_jupyter_graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sinju/miniconda3/envs/graphrag_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import (\n",
        "    RunnableBranch,\n",
        "    RunnableLambda,\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import Tuple, List, Optional\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import os\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.document_loaders import WikipediaLoader\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from neo4j import GraphDatabase\n",
        "from yfiles_jupyter_graphs import GraphWidget\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
        "from langchain_core.runnables import ConfigurableField, RunnableParallel, RunnablePassthrough\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t_fCDH8OwiHN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from neo4j import GraphDatabase\n",
        "from neo4j_graphrag.llm import OpenAILLM\n",
        "from neo4j_graphrag.retrievers import VectorRetriever\n",
        "from neo4j_graphrag.generation import GraphRAG\n",
        "from neo4j_graphrag.embeddings import OpenAIEmbeddings\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZFrOJOt7wk9t"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
        "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
        "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") or os.getenv(\"GRAPHRAG_LLM_API_KEY\")\n",
        "\n",
        "# ROOT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "OUTPUT_DIR = r\"/home/sinju/Documents/Nextwave/RAG/test_rag/output\"\n",
        "INDEX_NAME = \"text_units\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2rOTsLfPwoN1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Setup driver\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
        "\n",
        "# Setup embedder\n",
        "embedder = OpenAIEmbeddings(api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xjINMMzxwpHW"
      },
      "outputs": [],
      "source": [
        "\n",
        "def save_to_neo4j():\n",
        "    print(\"\\n--- Loading Graph into Neo4j ---\")\n",
        "\n",
        "    # Load parquet files\n",
        "    entities_path = os.path.join(OUTPUT_DIR, \"entities.parquet\")\n",
        "    rels_path = os.path.join(OUTPUT_DIR, \"relationships.parquet\")\n",
        "\n",
        "    if not os.path.exists(entities_path) or not os.path.exists(rels_path):\n",
        "        print(\"Error: Graph files not found in /output. Run the indexing pipeline first.\")\n",
        "        return\n",
        "\n",
        "    entities_df = pd.read_parquet(entities_path).dropna(subset=[\"title\"])\n",
        "    rels_df = pd.read_parquet(rels_path).dropna(subset=[\"source\", \"target\"])\n",
        "\n",
        "    # --- Normalize titles for matching ---\n",
        "    def normalize_text(s):\n",
        "        if pd.isna(s):\n",
        "            return None\n",
        "        return str(s).strip().upper()  # remove spaces, uppercase\n",
        "\n",
        "    entities_df['title'] = entities_df['title'].apply(normalize_text)\n",
        "    rels_df['source'] = rels_df['source'].apply(normalize_text)\n",
        "    rels_df['target'] = rels_df['target'].apply(normalize_text)\n",
        "\n",
        "    # --- Convert array fields to list for Neo4j ---\n",
        "    for col in ['text_unit_ids']:\n",
        "        if col in rels_df.columns:\n",
        "            rels_df[col] = rels_df[col].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
        "\n",
        "    entities_records = entities_df.astype(object).where(pd.notna(entities_df), None).to_dict(\"records\")\n",
        "    rels_records = rels_df.astype(object).where(pd.notna(rels_df), None).to_dict(\"records\")\n",
        "\n",
        "    with driver.session() as session:\n",
        "        # Create unique constraint on title\n",
        "        session.run(\"CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:Entity) REQUIRE e.title IS UNIQUE\")\n",
        "\n",
        "        # Ingest entities\n",
        "        print(f\"Ingesting {len(entities_records)} entities...\")\n",
        "        session.run(\n",
        "            \"\"\"\n",
        "            UNWIND $rows AS row\n",
        "            MERGE (e:Entity {title: row.title})\n",
        "            SET e += apoc.map.clean(row, ['title'], [])\n",
        "            \"\"\",\n",
        "            rows=entities_records\n",
        "        )\n",
        "\n",
        "        # Ingest relationships using title\n",
        "        print(f\"Ingesting {len(rels_records)} relationships...\")\n",
        "        failed_rels = []\n",
        "        for row in rels_records:\n",
        "            try:\n",
        "                result = session.run(\n",
        "                    \"\"\"\n",
        "                    MATCH (s:Entity {title: $source})\n",
        "                    MATCH (t:Entity {title: $target})\n",
        "                    MERGE (s)-[r:RELATIONSHIP {id: $id}]->(t)\n",
        "                    SET r += apoc.map.clean($props, ['id', 'source', 'target'], [])\n",
        "                    RETURN r\n",
        "                    \"\"\",\n",
        "                    {\"source\": row[\"source\"], \"target\": row[\"target\"], \"id\": row[\"id\"], \"props\": row}\n",
        "                )\n",
        "                if result.single() is None:\n",
        "                    failed_rels.append(row)\n",
        "            except Exception as e:\n",
        "                failed_rels.append({\"row\": row, \"error\": str(e)})\n",
        "\n",
        "        if failed_rels:\n",
        "            print(f\"Warning: {len(failed_rels)} relationships failed to insert:\")\n",
        "            for f in failed_rels[:5]:\n",
        "                print(f)\n",
        "        else:\n",
        "            print(\"--- All relationships ingested successfully ---\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8C4YuEw7wt2d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Save text units ---\n",
        "def save_text_units(parquet_file=\"output/text_units.parquet\"):\n",
        "    df = pd.read_parquet(parquet_file)\n",
        "    with driver.session() as session:\n",
        "        for _, row in df.iterrows():\n",
        "            embedding = embedder.embed_query(row[\"text\"]) if embedder else []\n",
        "            session.run(\n",
        "                \"\"\"\n",
        "                MERGE (t:TextUnit {id: $id})\n",
        "                SET t.text = $text, t.embedding = $embedding\n",
        "                \"\"\",\n",
        "                {\"id\": row[\"id\"], \"text\": row[\"text\"], \"embedding\": embedding}\n",
        "            )\n",
        "    print(f\"--- Ingested {len(df)} text units into Neo4j ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tPBO6_MXw0q-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Create vector index ---\n",
        "def create_vector_index(index_name=\"text_units\"):\n",
        "    with driver.session() as session:\n",
        "        session.run(f\"\"\"\n",
        "            CREATE VECTOR INDEX {index_name} IF NOT EXISTS\n",
        "            FOR (t:TextUnit) ON (t.embedding)\n",
        "        \"\"\")\n",
        "    print(f\"--- Vector index '{index_name}' created (or already exists) ---\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OoCTjUMmw1d-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_query_debug(query=\"Whats the age of elizabeth called\"):\n",
        "    retriever = VectorRetriever(driver, INDEX_NAME, embedder)\n",
        "    llm = OpenAILLM(model_name=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
        "    rag = GraphRAG(retriever=retriever, llm=llm)\n",
        "\n",
        "    # Perform RAG search\n",
        "    response = rag.search(query_text=query, retriever_config={\"top_k\": 5})\n",
        "\n",
        "    # LLM answer\n",
        "    print(\"\\n--- LLM-Generated Answer ---\")\n",
        "    print(response.answer)\n",
        "\n",
        "    # Print the context nodes used by the LLM\n",
        "    if hasattr(response, \"source_nodes\") and response.source_nodes:\n",
        "        print(\"\\n--- Context Passed to LLM ---\")\n",
        "        for i, node in enumerate(response.source_nodes, 1):\n",
        "            # each node is a dictionary containing at least 'text'\n",
        "            text = node.get(\"text\") if isinstance(node, dict) else str(node)\n",
        "            print(f\"{i}. {text}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9quKJW3rw3Lm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Loading Graph into Neo4j ---\n",
            "Ingesting 326 entities...\n",
            "Ingesting 350 relationships...\n",
            "--- All relationships ingested successfully ---\n",
            "--- Ingested 27 text units into Neo4j ---\n",
            "--- Vector index 'text_units' created (or already exists) ---\n",
            "\n",
            "--- LLM-Generated Answer ---\n",
            "The age of Elizabeth I is referred to as the \"Elizabethan era.\"\n"
          ]
        }
      ],
      "source": [
        "save_to_neo4j()\n",
        "save_text_units(\"output/text_units.parquet\")\n",
        "create_vector_index(INDEX_NAME)\n",
        "run_query_debug()\n",
        "driver.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b62f50c3674c478197818fa75d254f7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "GraphWidget(layout=Layout(height='800px', width='100%'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# directly show the graph resulting from the given Cypher query\n",
        "default_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t\"\n",
        "\n",
        "def showGraph(cypher: str = default_cypher):\n",
        "    # create a neo4j session to run queries\n",
        "    driver = GraphDatabase.driver(\n",
        "        uri = os.environ[\"NEO4J_URI\"],\n",
        "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
        "                os.environ[\"NEO4J_PASSWORD\"]))\n",
        "    session = driver.session()\n",
        "    widget = GraphWidget(graph = session.run(cypher).graph())\n",
        "    widget.node_label_mapping = 'id'\n",
        "    # display(widget)\n",
        "    return widget\n",
        "\n",
        "showGraph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API Usage for 2025-08-23:\n",
            "{'object': 'list', 'data': [{'organization_id': 'org-XOIaTvOT7o7SoUAZ0MxFItSW', 'organization_name': 'THE NYCG', 'aggregation_timestamp': 1755946800, 'n_requests': 1, 'operation': 'completion', 'snapshot_id': 'gpt-4o-mini-2024-07-18', 'n_context_tokens_total': 470, 'n_generated_tokens_total': 115, 'email': None, 'api_key_id': None, 'api_key_name': None, 'api_key_redacted': None, 'api_key_type': None, 'project_id': None, 'project_name': None, 'request_type': '', 'n_cached_context_tokens_total': 0, 'n_context_audio_tokens_total': 0, 'n_generated_audio_tokens_total': 0}], 'ft_data': [], 'dalle_api_data': [], 'whisper_api_data': [], 'tts_api_data': [], 'assistant_code_interpreter_data': [], 'retrieval_storage_data': []}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "\n",
        "date = (datetime.now(timezone.utc) - timedelta(days=1)).date()\n",
        "\n",
        "url = f\"https://api.openai.com/v1/usage?date={date}\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    usage_data = response.json()\n",
        "    print(f\"API Usage for {date}:\")\n",
        "    print(usage_data)\n",
        "else:\n",
        "    print(\"Error:\", response.status_code, response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "graphrag_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
